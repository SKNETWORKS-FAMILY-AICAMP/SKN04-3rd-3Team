from vector_db import initialize_vector_store
from utils import print_messages, create_insurance_file_mapping

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import ChatMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

from langchain_core.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
)
from dotenv import load_dotenv
from operator import itemgetter


load_dotenv()
chroma_db = initialize_vector_store()

st.set_page_config(
    page_title='ë³´í—˜ì™•ì´ ë˜ê³  ì‹¶ì–´',
    page_icon="ğŸ¦ˆ",
)

st.title("LangChain + Streamlit ì•±")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "store" not in st.session_state:
    st.session_state["store"] = dict()


print_messages()

def get_session_history(session_ids: str) -> BaseChatMessageHistory:
    print(session_ids)
    if session_ids not in st.session_state["store"]:
        st.session_state["store"][session_ids] = ChatMessageHistory()
    return st.session_state["store"][session_ids]

insurence = ['ë³´í—˜ì•½ê´€', 'DB', 'ë¡¯ë°', 'ì‚¼ì„±í™”ì¬', 'ìºë¡¯', 'í•˜ë‚˜', 'í˜„ëŒ€í•´ìƒ']

file_mapping = create_insurance_file_mapping(insurence)
selected_insurance = st.sidebar.selectbox(
    'ë³´í—˜ì•½ê´€',
    insurence
)

if selected_insurance == 'ë³´í—˜ì•½ê´€':
    retriever = chroma_db.as_retriever(
        search_kwargs={'k': 4}
    )
    source = 'ì „ì²´'
else:
    pdf_path = f'./data/{file_mapping.get(selected_insurance)}.pdf'
    retriever = chroma_db.as_retriever(
        search_kwargs={
            'k': 4,
            'filter': {'source': {'$eq': pdf_path}}
        }
    )
    source = file_mapping.get(selected_insurance)

if user_input :=st.chat_input('ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'):
    st.chat_message('user', avatar='https://media.discordapp.net/attachments/1304270859543773235/1305737598550933514/image0.jpg?ex=67341e66&is=6732cce6&hm=bbaba36f0b1e25ff00f86c81c4b4a5f9424246e6d5293fdccf388b9cf0b87bea&=&format=webp&width=582&height=542').write(f'{user_input}')
    st.session_state['messages'].append(ChatMessage(role="user", content=user_input))

    model = ChatOpenAI(model='gpt-4o-mini', temperature=0.1)
    prompt = ChatPromptTemplate.from_messages([
        (
            "system", 
            '''
            ë‹¹ì‹ ì€ ë³´í—˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ë‹¤ìŒ contextë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”: 
            {context}
            '''
        ),
        MessagesPlaceholder(variable_name='history'),
        (
            'human', " ì‚¬ìš©ì ì§ˆë¬¸:{question}"),
        (
            "system",
            """
            ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            ì¶œì²˜ë¥¼ ë¬¼ì–´ë³¼ê²½ìš° {source} ë¥¼ ì•Œë ¤ì¤˜
            """
        )
        ])
    
    chain = (
        {
            'context': itemgetter('question')
            | retriever,
            'question': itemgetter('question'),
            'history': itemgetter('history'),
            "source": lambda _: source
        }
        | prompt
        | model
    )

    chain_with_memory = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key='question',
        history_messages_key='history'
    )

    answer = chain_with_memory.invoke(
        {"question": user_input },
        config={"configurable": {"session_id": "abc123"}}
    )

    with st.chat_message('assistant', avatar="https://images-ext-1.discordapp.net/external/3g0sXbzVpODdQnppiIhtfQzzojtIgRMsLp00kLCyXNg/https/img.freepik.com/premium-photo/3d-style-chat-bot-robot-ai-app-icon-isolated-white-background-generative-ai_159242-25937.jpg?format=webp&width=782&height=588"):
        output = answer.content
        st.write(output)
        st.session_state['messages'].append(ChatMessage(role="assistant", content=output))



    
    


