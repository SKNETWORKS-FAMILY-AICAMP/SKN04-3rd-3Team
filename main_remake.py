# from chroma import chroma_db, documents
from utils import print_messages
from vector_db import initialize_vector_store, create_insurance_file_mapping
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.messages import ChatMessage
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.output_parsers import StrOutputParser

from langchain_community.document_transformers import LongContextReorder
from langchain.memory import ConversationBufferWindowMemory

from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import (
    PromptTemplate,
    ChatPromptTemplate,
    MessagesPlaceholder,
)
from dotenv import load_dotenv
from operator import itemgetter
load_dotenv()

# ChatGPT ëª¨ë¸ ì´ˆê¸°í™” (gpt-4o-mini ëª¨ë¸, temperature=0.3ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ëœ ì‘ë‹µ ìƒì„±)
model = ChatOpenAI(model='gpt-4o-mini', temperature=0.3)

# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ë¬¸ì„œ ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ê¸° ìœ„í•œ Chroma DB)
chroma_db = initialize_vector_store()

# ë¬¸ë§¥ ëŒ€í™”ë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ ì„¤ì •
memory = ConversationBufferWindowMemory(
    k=5,  # ìµœê·¼ 5ê°œì˜ ëŒ€í™”ë§Œ ìœ ì§€
    memory_key='chat_history',
    output_key='answer',
    return_messages=True
)

# ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(input_text):
    docs = retriever.invoke(input_text)
    context = "\n".join(doc.page_content for doc in docs)
    
    # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    chat_history = memory.load_memory_variables({})['chat_history']
    
    prompt = ChatPromptTemplate.from_template(template)
    parser = StrOutputParser()
    # chain êµ¬ì„± ìˆ˜ì •
    chain = prompt | model | parser
    # ì…ë ¥ ë°ì´í„° êµ¬ì„±
    input_data = {
        "context": context,
        "chat_history": chat_history,
        "question": input_text,
        "source": file_mapping.get(selected_insurance),
    }
    answer = chain.invoke(input_data)
    
    # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
    memory.save_context(
        {"input": input_text},
        {"answer": answer}
    )
    
    return answer

st.set_page_config(
    page_title='ë³´í—˜ì™•ì´ ë˜ê³  ì‹¶ì–´',
    page_icon="ğŸ¦ˆ",
)

st.title("LangChain + Streamlit ì•±")


# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” (ì„¸ì…˜ ìƒíƒœì— ì €ì¥)
if "messages" not in st.session_state:
    st.session_state["messages"] = []

print_messages()

if "store" not in st.session_state:
    st.session_state["store"] = dict()

insurence = ['ë³´í—˜ì•½ê´€', 'DB', 'ë¡¯ë°', 'ì‚¼ì„±í™”ì¬', 'ìºë¡¯', 'í•˜ë‚˜', 'í˜„ëŒ€í•´ìƒ']
# ì‚¬ìš© ì˜ˆì‹œ
file_mapping = create_insurance_file_mapping(insurence)
selected_insurance = st.sidebar.selectbox(
    'ë³´í—˜ì•½ê´€',
    insurence
)

# ì„ íƒëœ ë³´í—˜ì— ë”°ë¼ retriever ì„¤ì •
if selected_insurance == 'ë³´í—˜ì•½ê´€':
    retriever = chroma_db.as_retriever(
        search_kwargs={'k': 4}
    )
else:
    pdf_path = f'./data/{file_mapping.get(selected_insurance)}.pdf'
    retriever = chroma_db.as_retriever(
        search_kwargs={
            'k': 4,
            'filter': {'source': {'$eq': pdf_path}}
        }
    )

template = template = '''
ë‹¹ì‹ ì€ ë³´í—˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{context}

ì´ì „ ëŒ€í™” ê¸°ë¡:
{chat_history}

ì‚¬ìš©ì ì§ˆë¬¸:
{question}

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì¶œì²˜ë¥¼ ë¬¼ì–´ë³¼ê²½ìš° {source} ë¥¼ ì•Œë ¤ì¤˜
'''

# chat_placeholder = st.empty()
# with chat_placeholder.container():
#     for message in st.session_state.chat_messages.messages:
#         role = "ì‚¬ìš©ì" if message["role"] == "user" else "AI"
#         st.write(f"{role}: {message['content']}")

# retriever = chroma_db.as_retriever(search_kwargs={'k': 4})

# reordering = LongContextReorder()
# documents_reordered = reordering.transform_documents(documents)

# ###################################

# def reorder_documents(documents):
#     reordering = LongContextReorder()
#     reordered_documents = reordering.transform_documents(documents)
#     documents_joined = '\n'.join([docs.page_content for docs in reordered_documents])

#     return documents_joined


# # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
# user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
# if st.button('ë©”ì„¸ì§€ ì „ì†¡'):
#     # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
#     st.session_state.chat_messages.messages.append({"role": "user", "content": user_input})
    
#     # AI ì‘ë‹µ ìƒì„± ë° ì €ì¥
#     try:
#         # ì£¼ìš” ì½”ë“œ
#         response = generate_response(user_input)
#         st.session_state.chat_messages.messages.append({"role": "assistant", "content": response})

#     except Exception as e:
#         st.error(f"Error: {e}")

if user_input :=st.chat_input('ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'):
    
    st.chat_message('user').write(f'{user_input}')
    #st.session_state['messages'].append(("user", user_input))
    st.session_state['messages'].append(ChatMessage(role="user", content=user_input))

    with st.chat_message('assistant', avatar="https://images-ext-1.discordapp.net/external/3g0sXbzVpODdQnppiIhtfQzzojtIgRMsLp00kLCyXNg/https/img.freepik.com/premium-photo/3d-style-chat-bot-robot-ai-app-icon-isolated-white-background-generative-ai_159242-25937.jpg?format=webp&width=782&height=588"):
        
       #  message = f'ë‹¹ì‹ ì´ ì…ë ¥í•œ ë‚´ìš©: {user_input}'
        output = generate_response(user_input)
        st.write(output)
        st.session_state['messages'].append(ChatMessage(role="assistant", content=output))


    
    
    


